{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target prediction: Progression\n",
      "processed_paths ['../data/Lung/processed/data_Progression_train.pt']\n",
      "Target prediction: Progression\n",
      "processed_paths ['../data/Lung/processed/data_Progression_test.pt']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from dataset import TissueDataset, LungDataset\n",
    "train_dataset = LungDataset(os.path.join(f\"../data/Lung\"), \"Progression\", train=True)\n",
    "test_dataset = LungDataset(os.path.join(f\"../data/Lung\"), \"Progression\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stratified_cv_folds_fixed(dataset, clinical_outcome_label, n_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Create stratified cross-validation folds with equal class representation and patient-level stratification.\n",
    "    FIXED VERSION - No duplicate indices.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : PyTorch Dataset\n",
    "        The dataset containing samples with clinical outcomes\n",
    "    clinical_outcome_label : str\n",
    "        The clinical outcome of interest (e.g., \"Progression\")\n",
    "    n_folds : int, default=5\n",
    "        Number of cross-validation folds\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary where keys are fold numbers (0 to n_folds-1) and values are \n",
    "           lists containing [train_indices, validation_indices]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract sample information\n",
    "    sample_data = []\n",
    "    \n",
    "    for idx, data in enumerate(dataset):\n",
    "        sample_id = data.sample_id\n",
    "        # Extract patient ID using the helper function\n",
    "        patient_id = extract_patient_id(sample_id)\n",
    "        \n",
    "        sample_data.append({\n",
    "            'sample_idx': idx,\n",
    "            'sample_id': sample_id,\n",
    "            'patient_id': patient_id,\n",
    "            'outcome': data.y.item() if hasattr(data.y, 'item') else data.y\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(df)\n",
    "    # Count class distribution\n",
    "    class_counts = df['outcome'].value_counts()\n",
    "    print(f\"Original class distribution:\")\n",
    "    for class_val, count in class_counts.items():\n",
    "        print(f\"  Class {class_val}: {count} samples\")\n",
    "    \n",
    "    # Find the minority class count\n",
    "    minority_class_count = min(class_counts.values)\n",
    "    print(f\"Minority class count: {minority_class_count}\")\n",
    "    \n",
    "    # Get samples for each class\n",
    "    class_0_samples = df[df['outcome'] == 0].copy()\n",
    "    class_1_samples = df[df['outcome'] == 1].copy()\n",
    "    \n",
    "    # Downsample majority class to match minority class\n",
    "    if len(class_0_samples) > minority_class_count:\n",
    "        class_0_samples = class_0_samples.sample(n=minority_class_count, random_state=random_state)\n",
    "    if len(class_1_samples) > minority_class_count:\n",
    "        class_1_samples = class_1_samples.sample(n=minority_class_count, random_state=random_state)\n",
    "    \n",
    "    # Combine balanced samples\n",
    "    balanced_df = pd.concat([class_0_samples, class_1_samples]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Balanced class distribution:\")\n",
    "    balanced_class_counts = balanced_df['outcome'].value_counts()\n",
    "    for class_val, count in balanced_class_counts.items():\n",
    "        print(f\"  Class {class_val}: {count} samples\")\n",
    "    \n",
    "    # Create patient-level stratification\n",
    "    # Get unique patients and their outcomes\n",
    "    patient_outcomes = balanced_df.groupby('patient_id')['outcome'].first().reset_index()\n",
    "    \n",
    "    # Create stratified folds at patient level\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    folds_dict = {}\n",
    "    \n",
    "    for fold_idx, (train_patient_indices, val_patient_indices) in enumerate(skf.split(patient_outcomes['patient_id'], patient_outcomes['outcome'])):\n",
    "        # Get patient IDs for this fold\n",
    "        train_patients = patient_outcomes.iloc[train_patient_indices]['patient_id'].tolist()\n",
    "        val_patients = patient_outcomes.iloc[val_patient_indices]['patient_id'].tolist()\n",
    "        \n",
    "        # Get sample indices for training and validation\n",
    "        train_sample_indices = balanced_df[balanced_df['patient_id'].isin(train_patients)]['sample_idx'].tolist()\n",
    "        val_sample_indices = balanced_df[balanced_df['patient_id'].isin(val_patients)]['sample_idx'].tolist()\n",
    "        \n",
    "        folds_dict[fold_idx] = [train_sample_indices, val_sample_indices]\n",
    "        \n",
    "        # Print fold statistics\n",
    "        train_outcomes = balanced_df[balanced_df['sample_idx'].isin(train_sample_indices)]['outcome']\n",
    "        val_outcomes = balanced_df[balanced_df['sample_idx'].isin(val_sample_indices)]['outcome']\n",
    "        \n",
    "        print(f\"\\nFold {fold_idx}:\")\n",
    "        print(f\"  Training: {len(train_sample_indices)} samples from {len(train_patients)} patients\")\n",
    "        print(f\"  Validation: {len(val_sample_indices)} samples from {len(val_patients)} patients\")\n",
    "        print(f\"  Training class distribution: {train_outcomes.value_counts().to_dict()}\")\n",
    "        print(f\"  Validation class distribution: {val_outcomes.value_counts().to_dict()}\")\n",
    "    \n",
    "    return folds_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 1308\n",
      "0.15284974093264247\n",
      "0.8471502590673575\n",
      "0.15284974093264247\n",
      "0.8471502590673575\n"
     ]
    }
   ],
   "source": [
    "num_of_ones = 0\n",
    "num_of_zeros = 0\n",
    "for data in train_dataset:\n",
    "    if data[\"y\"][0] == 1:\n",
    "        num_of_ones+= 1\n",
    "    else:\n",
    "        num_of_zeros += 1\n",
    "print(num_of_ones, num_of_zeros)\n",
    "print(num_of_ones/len(train_dataset))\n",
    "print(num_of_zeros/len(train_dataset))\n",
    "print(num_of_ones/len(train_dataset))\n",
    "print(num_of_zeros/len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating folds...\n",
      "Fold 0: No data leakage detected\n",
      "Fold 1: No data leakage detected\n",
      "Fold 2: No data leakage detected\n",
      "Fold 3: No data leakage detected\n",
      "Fold 4: No data leakage detected\n",
      "All folds validated successfully\n"
     ]
    }
   ],
   "source": [
    "def validate_folds(dataset, folds):\n",
    "    \"\"\"\n",
    "    Validate that the folds are properly stratified and have no data leakage.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : PyTorch Dataset\n",
    "        The dataset containing samples\n",
    "    folds : dict\n",
    "        Dictionary containing fold information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if validation passes, False otherwise\n",
    "    \"\"\"\n",
    "    print(\"Validating folds...\")\n",
    "    \n",
    "    # Check for data leakage (same patient in train and val)\n",
    "    for fold_idx, (train_indices, val_indices) in folds.items():\n",
    "        train_patients = set()\n",
    "        val_patients = set()\n",
    "        \n",
    "        # Get patient IDs for training set\n",
    "        for idx in train_indices:\n",
    "            sample_id = dataset[idx].sample_id\n",
    "            patient_id = extract_patient_id(sample_id)\n",
    "            train_patients.add(patient_id)\n",
    "        \n",
    "        # Get patient IDs for validation set\n",
    "        for idx in val_indices:\n",
    "            sample_id = dataset[idx].sample_id\n",
    "            patient_id = extract_patient_id(sample_id)\n",
    "            val_patients.add(patient_id)\n",
    "        \n",
    "        # Check for overlap\n",
    "        overlap = train_patients.intersection(val_patients)\n",
    "        if overlap:\n",
    "            print(f\"Data leakage detected in fold {fold_idx}: {overlap}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"Fold {fold_idx}: No data leakage detected\")\n",
    "\n",
    "    print(\"All folds validated successfully\")\n",
    "    return True\n",
    "\n",
    "# Test the validation function\n",
    "validation_result = validate_folds(train_dataset, folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example cross-validation usage:\n",
      "\n",
      "--- Fold 0 ---\n",
      "Training samples: 379\n",
      "Validation samples: 93\n",
      "Training class distribution: {0: 187, 1: 192}\n",
      "Validation class distribution: {0: 49, 1: 44}\n",
      "First 3 training sample IDs: ['LUAD_D017_LUAD_D017', 'LUAD_D094lr_LUAD_D094', 'LUAD_D208ur_LUAD_D208']\n",
      "First 3 validation sample IDs: ['LUAD_D035lr_LUAD_D035', 'LUAD_D140lr_LUAD_D140', 'LUAD_D193ll_LUAD_D193']\n",
      "\n",
      "--- Fold 1 ---\n",
      "Training samples: 372\n",
      "Validation samples: 100\n",
      "Training class distribution: {0: 185, 1: 187}\n",
      "Validation class distribution: {0: 51, 1: 49}\n",
      "First 3 training sample IDs: ['LUAD_D017_LUAD_D017', 'LUAD_D094lr_LUAD_D094', 'LUAD_D026ll_LUAD_D026']\n",
      "First 3 validation sample IDs: ['LUAD_D208ur_LUAD_D208', 'LUAD_D181ur_LUAD_D181', 'LUAD_D361ul_LUAD_D361']\n",
      "\n",
      "--- Fold 2 ---\n",
      "Training samples: 375\n",
      "Validation samples: 97\n",
      "Training class distribution: {0: 185, 1: 190}\n",
      "Validation class distribution: {0: 51, 1: 46}\n",
      "First 3 training sample IDs: ['LUAD_D017_LUAD_D017', 'LUAD_D094lr_LUAD_D094', 'LUAD_D208ur_LUAD_D208']\n",
      "First 3 validation sample IDs: ['LUAD_D026ll_LUAD_D026', 'LUAD_D402_LUAD_D402', 'LUAD_D026ur_LUAD_D026']\n",
      "\n",
      "--- Fold 3 ---\n",
      "Training samples: 375\n",
      "Validation samples: 97\n",
      "Training class distribution: {0: 192, 1: 183}\n",
      "Validation class distribution: {0: 44, 1: 53}\n",
      "First 3 training sample IDs: ['LUAD_D094lr_LUAD_D094', 'LUAD_D208ur_LUAD_D208', 'LUAD_D026ll_LUAD_D026']\n",
      "First 3 validation sample IDs: ['LUAD_D017_LUAD_D017', 'LUAD_D010ll_LUAD_D010', 'LUAD_D119lr_LUAD_D119']\n",
      "\n",
      "--- Fold 4 ---\n",
      "Training samples: 387\n",
      "Validation samples: 85\n",
      "Training class distribution: {0: 195, 1: 192}\n",
      "Validation class distribution: {0: 41, 1: 44}\n",
      "First 3 training sample IDs: ['LUAD_D017_LUAD_D017', 'LUAD_D208ur_LUAD_D208', 'LUAD_D026ll_LUAD_D026']\n",
      "First 3 validation sample IDs: ['LUAD_D094lr_LUAD_D094', 'LUAD_D367lr_LUAD_D367', 'LUAD_D217ll_LUAD_D217']\n"
     ]
    }
   ],
   "source": [
    "# Example usage: How to use the folds for cross-validation\n",
    "def example_cross_validation_usage(dataset, folds):\n",
    "    \"\"\"\n",
    "    Example of how to use the folds for cross-validation training.\n",
    "    \"\"\"\n",
    "    print(\"Example cross-validation usage:\")\n",
    "    \n",
    "    for fold_idx, (train_indices, val_indices) in folds.items():\n",
    "        print(f\"\\n--- Fold {fold_idx} ---\")\n",
    "        \n",
    "        # Create training and validation datasets\n",
    "        train_samples = [dataset[i] for i in train_indices]\n",
    "        val_samples = [dataset[i] for i in val_indices]\n",
    "        \n",
    "        print(f\"Training samples: {len(train_samples)}\")\n",
    "        print(f\"Validation samples: {len(val_samples)}\")\n",
    "        \n",
    "        # Example: Get class distribution for this fold\n",
    "        train_labels = [sample.y.item() if hasattr(sample.y, 'item') else sample.y for sample in train_samples]\n",
    "        val_labels = [sample.y.item() if hasattr(sample.y, 'item') else sample.y for sample in val_samples]\n",
    "        \n",
    "        train_class_dist = {0: train_labels.count(0), 1: train_labels.count(1)}\n",
    "        val_class_dist = {0: val_labels.count(0), 1: val_labels.count(1)}\n",
    "        \n",
    "        print(f\"Training class distribution: {train_class_dist}\")\n",
    "        print(f\"Validation class distribution: {val_class_dist}\")\n",
    "        \n",
    "        # Here you would typically:\n",
    "        # 1. Create DataLoaders for train and val sets\n",
    "        # 2. Train your model on train_samples\n",
    "        # 3. Evaluate on val_samples\n",
    "        # 4. Store the results\n",
    "        \n",
    "        # For demonstration, just show the first few sample IDs\n",
    "        print(f\"First 3 training sample IDs: {[sample.sample_id for sample in train_samples[:3]]}\")\n",
    "        print(f\"First 3 validation sample IDs: {[sample.sample_id for sample in val_samples[:3]]}\")\n",
    "\n",
    "# Run the example\n",
    "example_cross_validation_usage(train_dataset, folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the FIXED function...\n",
      "      sample_idx              sample_id patient_id  outcome\n",
      "0              0  LUAD_D352ur_LUAD_D352  LUAD_D352        0\n",
      "1              1  LUAD_D397ll_LUAD_D397  LUAD_D397        0\n",
      "2              2  LUAD_D164lr_LUAD_D164  LUAD_D164        0\n",
      "3              3  LUAD_D198lr_LUAD_D198  LUAD_D198        1\n",
      "4              4  LUAD_D394ll_LUAD_D394  LUAD_D394        0\n",
      "...          ...                    ...        ...      ...\n",
      "1539        1539  LUAD_D275ur_LUAD_D275  LUAD_D275        0\n",
      "1540        1540    LUAD_D260_LUAD_D260  LUAD_D260        0\n",
      "1541        1541  LUAD_D212lr_LUAD_D212  LUAD_D212        0\n",
      "1542        1542  LUAD_D363ur_LUAD_D363  LUAD_D363        0\n",
      "1543        1543  LUAD_D036ul_LUAD_D036  LUAD_D036        0\n",
      "\n",
      "[1544 rows x 4 columns]\n",
      "Original class distribution:\n",
      "  Class 0: 1308 samples\n",
      "  Class 1: 236 samples\n",
      "Minority class count: 236\n",
      "Balanced class distribution:\n",
      "  Class 0: 236 samples\n",
      "  Class 1: 236 samples\n",
      "\n",
      "Fold 0:\n",
      "  Training: 379 samples from 192 patients\n",
      "  Validation: 93 samples from 48 patients\n",
      "  Training class distribution: {1: 192, 0: 187}\n",
      "  Validation class distribution: {0: 49, 1: 44}\n",
      "\n",
      "Fold 1:\n",
      "  Training: 372 samples from 192 patients\n",
      "  Validation: 100 samples from 48 patients\n",
      "  Training class distribution: {1: 187, 0: 185}\n",
      "  Validation class distribution: {0: 51, 1: 49}\n",
      "\n",
      "Fold 2:\n",
      "  Training: 375 samples from 192 patients\n",
      "  Validation: 97 samples from 48 patients\n",
      "  Training class distribution: {1: 190, 0: 185}\n",
      "  Validation class distribution: {0: 51, 1: 46}\n",
      "\n",
      "Fold 3:\n",
      "  Training: 375 samples from 192 patients\n",
      "  Validation: 97 samples from 48 patients\n",
      "  Training class distribution: {0: 192, 1: 183}\n",
      "  Validation class distribution: {1: 53, 0: 44}\n",
      "\n",
      "Fold 4:\n",
      "  Training: 387 samples from 192 patients\n",
      "  Validation: 85 samples from 48 patients\n",
      "  Training class distribution: {0: 195, 1: 192}\n",
      "  Validation class distribution: {1: 44, 0: 41}\n",
      "Validating folds...\n",
      "Fold 0: No data leakage detected\n",
      "Fold 1: No data leakage detected\n",
      "Fold 2: No data leakage detected\n",
      "Fold 3: No data leakage detected\n",
      "Fold 4: No data leakage detected\n",
      "All folds validated successfully\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed function\n",
    "print(\"Testing the FIXED function...\")\n",
    "folds_fixed = create_stratified_cv_folds_fixed(train_dataset, \"Progression\", n_folds=5, random_state=42)\n",
    "\n",
    "# Validate the fixed folds\n",
    "validation_result = validate_folds(train_dataset, folds_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the FIXED function with corrected patient ID extraction...\n",
      "      sample_idx              sample_id patient_id  outcome\n",
      "0              0  LUAD_D352ur_LUAD_D352  LUAD_D352        0\n",
      "1              1  LUAD_D397ll_LUAD_D397  LUAD_D397        0\n",
      "2              2  LUAD_D164lr_LUAD_D164  LUAD_D164        0\n",
      "3              3  LUAD_D198lr_LUAD_D198  LUAD_D198        1\n",
      "4              4  LUAD_D394ll_LUAD_D394  LUAD_D394        0\n",
      "...          ...                    ...        ...      ...\n",
      "1539        1539  LUAD_D275ur_LUAD_D275  LUAD_D275        0\n",
      "1540        1540    LUAD_D260_LUAD_D260  LUAD_D260        0\n",
      "1541        1541  LUAD_D212lr_LUAD_D212  LUAD_D212        0\n",
      "1542        1542  LUAD_D363ur_LUAD_D363  LUAD_D363        0\n",
      "1543        1543  LUAD_D036ul_LUAD_D036  LUAD_D036        0\n",
      "\n",
      "[1544 rows x 4 columns]\n",
      "Original class distribution:\n",
      "  Class 0: 1308 samples\n",
      "  Class 1: 236 samples\n",
      "Minority class count: 236\n",
      "Balanced class distribution:\n",
      "  Class 0: 236 samples\n",
      "  Class 1: 236 samples\n",
      "\n",
      "Fold 0:\n",
      "  Training: 379 samples from 192 patients\n",
      "  Validation: 93 samples from 48 patients\n",
      "  Training class distribution: {1: 192, 0: 187}\n",
      "  Validation class distribution: {0: 49, 1: 44}\n",
      "\n",
      "Fold 1:\n",
      "  Training: 372 samples from 192 patients\n",
      "  Validation: 100 samples from 48 patients\n",
      "  Training class distribution: {1: 187, 0: 185}\n",
      "  Validation class distribution: {0: 51, 1: 49}\n",
      "\n",
      "Fold 2:\n",
      "  Training: 375 samples from 192 patients\n",
      "  Validation: 97 samples from 48 patients\n",
      "  Training class distribution: {1: 190, 0: 185}\n",
      "  Validation class distribution: {0: 51, 1: 46}\n",
      "\n",
      "Fold 3:\n",
      "  Training: 375 samples from 192 patients\n",
      "  Validation: 97 samples from 48 patients\n",
      "  Training class distribution: {0: 192, 1: 183}\n",
      "  Validation class distribution: {1: 53, 0: 44}\n",
      "\n",
      "Fold 4:\n",
      "  Training: 387 samples from 192 patients\n",
      "  Validation: 85 samples from 48 patients\n",
      "  Training class distribution: {0: 195, 1: 192}\n",
      "  Validation class distribution: {1: 44, 0: 41}\n",
      "Validating folds...\n",
      "Fold 0: No data leakage detected\n",
      "Fold 1: No data leakage detected\n",
      "Fold 2: No data leakage detected\n",
      "Fold 3: No data leakage detected\n",
      "Fold 4: No data leakage detected\n",
      "All folds validated successfully\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed function with corrected patient ID extraction\n",
    "print(\"Testing the FIXED function with corrected patient ID extraction...\")\n",
    "folds_corrected = create_stratified_cv_folds_fixed(train_dataset, \"Progression\", n_folds=5, random_state=42)\n",
    "\n",
    "# Validate the corrected folds\n",
    "validation_result = validate_folds(train_dataset, folds_corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing patient ID extraction with actual dataset samples:\n",
      "First 10 samples from the dataset:\n",
      "  Sample 0: LUAD_D352ur_LUAD_D352 -> Patient: LUAD_D352\n",
      "  Sample 1: LUAD_D397ll_LUAD_D397 -> Patient: LUAD_D397\n",
      "  Sample 2: LUAD_D164lr_LUAD_D164 -> Patient: LUAD_D164\n",
      "  Sample 3: LUAD_D198lr_LUAD_D198 -> Patient: LUAD_D198\n",
      "  Sample 4: LUAD_D394ll_LUAD_D394 -> Patient: LUAD_D394\n",
      "  Sample 5: LUAD_D394ll_LUAD_D394 -> Patient: LUAD_D394\n",
      "  Sample 6: LUAD_D244ur_LUAD_D244 -> Patient: LUAD_D244\n",
      "  Sample 7: LUAD_D023ul_LUAD_D023 -> Patient: LUAD_D023\n",
      "  Sample 8: LUAD_D254lr_LUAD_D254 -> Patient: LUAD_D254\n",
      "  Sample 9: LUAD_D297lr_LUAD_D297 -> Patient: LUAD_D297\n",
      "\n",
      "Checking patient ID patterns:\n",
      "Unique patient IDs found in first 50 samples: 48\n",
      "Sample patient IDs: ['LUAD_D001', 'LUAD_D002', 'LUAD_D008', 'LUAD_D023', 'LUAD_D028', 'LUAD_D032', 'LUAD_D041', 'LUAD_D042', 'LUAD_D043', 'LUAD_D053']...\n"
     ]
    }
   ],
   "source": [
    "# Test patient ID extraction with actual sample IDs from the dataset\n",
    "print(\"Testing patient ID extraction with actual dataset samples:\")\n",
    "print(\"First 10 samples from the dataset:\")\n",
    "\n",
    "for i in range(min(10, len(train_dataset))):\n",
    "    sample_id = train_dataset[i].sample_id\n",
    "    patient_id = extract_patient_id(sample_id)\n",
    "    print(f\"  Sample {i}: {sample_id} -> Patient: {patient_id}\")\n",
    "\n",
    "# Check for any patterns in patient IDs\n",
    "print(\"\\nChecking patient ID patterns:\")\n",
    "patient_ids = set()\n",
    "for i in range(min(50, len(train_dataset))):  # Check first 50 samples\n",
    "    sample_id = train_dataset[i].sample_id\n",
    "    patient_id = extract_patient_id(sample_id)\n",
    "    patient_ids.add(patient_id)\n",
    "\n",
    "print(f\"Unique patient IDs found in first 50 samples: {len(patient_ids)}\")\n",
    "print(f\"Sample patient IDs: {sorted(list(patient_ids))[:10]}...\")  # Show first 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pid = \"LUAD_D001ll_LUAD_D001\"\n",
    "path = \"/home/rifaioglu/projects/GNNClinicalOutcomePrediction/data/Lung\"\n",
    "with open(os.path.join(path, \"raw\", f'{img_pid}_features.pickle'), 'rb') as handle:\n",
    "                    feature_arr = pickle.load(handle)\n",
    "                    feature_arr = np.array(feature_arr)\n",
    "with open(os.path.join(path, \"raw\", f'{img_pid}_edge_index_length.pickle'), 'rb') as handle:\n",
    "    edge_index_arr, edge_length_arr = pickle.load(handle)\n",
    "    edge_index_arr = np.array(edge_index_arr)\n",
    "\n",
    "with open(os.path.join(path, \"raw\", f'{img_pid}_ct_class.pickle'), 'rb') as handle:\n",
    "    ct_class_arr = pickle.load(handle)\n",
    "    ct_class_arr = np.array(ct_class_arr)\n",
    "\n",
    "with open(os.path.join(path, \"raw\", f'{img_pid}_coordinates.pickle'), 'rb') as handle:\n",
    "    coordinates_arr = pickle.load(handle)\n",
    "    coordinates_arr = np.array(coordinates_arr)\n",
    "\n",
    "with open(os.path.join(path, \"raw\", f'{img_pid}_clinical_info.pickle'), 'rb') as handle:\n",
    "    clinical_info_dict = pickle.load(handle)\n",
    "    clinical_info_dict = np.array(clinical_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import data_processing_lung_pipeline\n",
    "data_processing_lung_pipeline(\"/home/rifaioglu/projects/GNNClinicalOutcomePrediction/data/Lung/raw/merged_preprocessed_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
